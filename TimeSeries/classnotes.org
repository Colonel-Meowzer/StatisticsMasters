#+TITLE:     Time Series Analysis Class Notes
#+AUTHOR:    Dustin Leatherman

* Characteristics of Time Series (2020/01/09)
- Must be correlation between data points which limits conventional statistical
  analysis.
- One variable, $x_t$, will be used in this course

*Important Questions to Ask*
- What patterns are visible over time?
- How can correlation between observations be used to help with the model?
- Can future state be predicted using this data?

*Problem*: We don't know how many previous time points should be used to predict
the current value.

*General Tips*
- if non-constant variance, transform the predictors
- Find assumptions, then continue modeling
- Time is generally treated as discrete values instead of continuous

*Stochastic Process*: collection of random variables, $x_t$, indexed by $t$
- *Realization*: Realization of a stochastic process.

*Time Series*: collection of randome variables indexed and ordered by time

*White Noise*: $w_t \sim N(0, \sigma_w^2)$

One way to "smooth" a time series is to introduce a moving average.

MA(1): $x_t = \beta w_{t - 1} + w_t$

AR(1): $x_t = \beta x_{t - 1} + w_t$

\begin{equation}
\begin{split}
E(x_t) = & E(\beta X_{t - 1} + w_t)\\
= & \beta E(x_{t - 1}) + E(w_t)\\
= & ...\\
= & 0
\end{split}
\end{equation}

- $0 \leq \beta \leq 1$

$\gamma(s, t) = cov(x_s, x_t) = E[(x_s - \mu_s)(x_t - \mu_t)] \forall \ s,t$

if s == t, $cov(x_s, x_s) = var(x_s)$

$\gamma(s, t) = \begin{cases}
\sigma_w^2 & s = t\\
0 & s \neq t
\end{cases}$
- given $w_t \sim ind \ N(0, \sigma_w^2)$

** Moving Average

Let $m_t = \frac{w_t + w_{t - 1} + w_{t - 2}}{3}$
\begin{equation}
\begin{split}
E[(m_s - \mu_s)(m_t - \mu_t)] = & E(m_s m_t)\\
= & \frac{1}{9}E[(w_s + w_{s - 1} + w_{s - 2})(w_t + w_{t - 1} + w_{t - 2})]
\end{split}
\end{equation}

_s = t_
\begin{equation}
\begin{split}
E(m_t^2) = & var(m_t) + E(m_t)^2\\
= & \frac{1}{9} var(w_t + w_{t - 1} + w_{t - 2}) + 0\\
= & \frac{1}{9} (var(w_t) + var(w_{t - 1} + var(w_{t - 2})))\\
= & \frac{1}{9} (1 + 1 + 1)\\
= & \frac{3}{9}
\end{split}
\end{equation}

_s = t - 1_: $E(m_{t - 1}, m_t) = \frac{2}{9}$

_s = t - 2_: $E(m_{t - 2}, m_t) = \frac{1}{9}$

_s = t - 3_: $E(m_{t - 3}, m_t) = 0$

$\gamma(s, t) = \begin{cases}
\frac{3}{9} & s = t\\
\frac{2}{9} & |s - t| = 1\\
\frac{1}{9} & |s - t| = 2\\
0 & |s - t| \geq 3
\end{cases}$

** Autocorrelation

$\rho_{xy} = \frac{cov(x, y)}{\sqrt{var(x)} \sqrt{var(y)}}$

*AR*: $\rho(s, t) = \begin{cases}
1 & s = t\\
0 & s \neq t
\end{cases}$

*MA*: $\rho(s, t) = \begin{cases}
1 & s = t\\
\frac{2}{3} & |s - t| = 1\\
\frac{1}{3} & |s - t| = 2\\
0 & |s - t| \geq 3
\end{cases}$

positve linear dependence = smooth
negative linear dependence = choppy

** Stationarity
*Strict stationary time series*: the probabalistic behavior of $x_t, ..., x_{tk}$
os the exact same as the shifted set $x_{t + h}, ..., x_{tk + h}$ for any
collection of time points $[t_1, t_k]$ for any $k = 1, 2,...$

$P(x_q \leq c_1, x_2 \leq c_2) = P(x_{10} \leq c_q, x_{11} \leq c_2)$

This is almost never used in practice because it is /too/ strict.

*Weakly Stationary Time Series*: The first two moments (mean, covariance) of the
time series are invariant to time shifts

$E(x_t) = \mu \forall t$

$\gamma(t, t + h) = \gamma(0, h) \forall t$

- $\mu$ and $\gamma(0, h)$ are /not/ functions of t
- Assumption of *Equal Variance*
- $\gamma(h) = \gamma(-h)$ if weakly stationary

\begin{equation}
\begin{split}
\rho(t, t + h) = & \frac{\gamma(t, t + h)}{\sqrt{\gamma(t, t)} \sqrt{\gamma(t +
h, t + h)}}\\
 = & \frac{\gamma(h)}{\sqrt{\gamma(0)} \sqrt{\gamma(0)}}\\
 = & \frac{\gamma(h)}{\gamma(0)}
\end{split}
\end{equation}

Is there a correlation between lags?
$H_0: \ \rho(h) = 0$
$H_A: \ \rho(h) \neq 0$


*Sample Mean*: $\bar{x} = \frac{1}{n} \Sigma x_t$

*Sample Covariance*: $\hat{\gamma(h)} = \frac{1}{n} \sum_{t = 1}^{n - h} (x_{t +
 h} - \bar{x}) (x_t - \bar{x})$
